{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/georgianpartners/Multimodal-Toolkit/blob/master/notebooks/text_w_tabular_classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a BertWithTabular Model for Clothing Review Recommendation Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This guide follows closely with the [example](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/trainer/01_text_classification.ipynb#scrollTo=bwl3I_VGAZXb) from HuggingFace for text classificaion on the GLUE dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Install `transformers` from master, and also clone the repo to get some utility files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/georgianpartners/Multimodal-Toolkit.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All imports are here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from typing import Callable, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pformat\n",
    "from scipy.special import softmax\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    EvalPrediction,\n",
    "    set_seed\n",
    ")\n",
    "curr_dir = os.getcwd()\n",
    "sys.path.insert(0, os.path.join(curr_dir, 'Multimodal-Toolkit'))\n",
    "\n",
    "from multimodal_exp_args import MultimodalDataTrainingArguments, ModelArguments, OurTrainingArguments\n",
    "from evaluation import calc_classification_metrics, calc_regression_metrics\n",
    "from multimodal.data.load_data import load_data_from_folder\n",
    "from multimodal.model.tabular_config import TabularConfig\n",
    "from multimodal.model.tabular_modeling_auto import AutoModelWithTabular\n",
    "from util import create_dir_if_not_exists, get_args_info_as_str\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Our dataset is the [Womens Clothing E-Commerce Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) dataset from kaggle. It contains reviews written by customers about clothing items as well as whether they recommend the data or not. After obtaining from kaggle, the dataset has been randomly split into train, val, test based on the 8:1:1 split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples train-val-test\n",
      "18788 2349 2349\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = os.path.join(curr_dir, 'Multimodal-Toolkit', 'datasets', 'Womens_Clothing_E-Commerce_Reviews')\n",
    "train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'), index_col=0)\n",
    "val_df = pd.read_csv(os.path.join(DATA_DIR, 'val.csv'), index_col=0)\n",
    "test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'), index_col=0)\n",
    "print('Num examples train-val-test')\n",
    "print(len(train_df), len(val_df), len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us take a look at what the dataset looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12515</th>\n",
       "      <td>936</td>\n",
       "      <td>21</td>\n",
       "      <td>Pretty but not for me</td>\n",
       "      <td>This sweater is very pretty, i love the knit a...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Sweaters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20723</th>\n",
       "      <td>995</td>\n",
       "      <td>36</td>\n",
       "      <td>Beautiful</td>\n",
       "      <td>As beautiful as in the picture. couldn't go wr...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Skirts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17409</th>\n",
       "      <td>869</td>\n",
       "      <td>47</td>\n",
       "      <td>Adorable and comfortable!</td>\n",
       "      <td>Just bought this in black at my local store an...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Knits</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7983</th>\n",
       "      <td>833</td>\n",
       "      <td>29</td>\n",
       "      <td>Must have, elegant, chic</td>\n",
       "      <td>This top! i was hesitant to try this on becaus...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5195</th>\n",
       "      <td>1059</td>\n",
       "      <td>38</td>\n",
       "      <td>Very flattering fit</td>\n",
       "      <td>This is a great pair of trousers for work but ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clothing ID  Age                      Title  \\\n",
       "12515          936   21      Pretty but not for me   \n",
       "20723          995   36                  Beautiful   \n",
       "17409          869   47  Adorable and comfortable!   \n",
       "7983           833   29   Must have, elegant, chic   \n",
       "5195          1059   38        Very flattering fit   \n",
       "\n",
       "                                             Review Text  Rating  \\\n",
       "12515  This sweater is very pretty, i love the knit a...       3   \n",
       "20723  As beautiful as in the picture. couldn't go wr...       5   \n",
       "17409  Just bought this in black at my local store an...       5   \n",
       "7983   This top! i was hesitant to try this on becaus...       5   \n",
       "5195   This is a great pair of trousers for work but ...       5   \n",
       "\n",
       "       Recommended IND  Positive Feedback Count   Division Name  \\\n",
       "12515                1                        1  General Petite   \n",
       "20723                1                        0         General   \n",
       "17409                1                        4         General   \n",
       "7983                 1                        3         General   \n",
       "5195                 1                        1  General Petite   \n",
       "\n",
       "      Department Name Class Name  \n",
       "12515            Tops   Sweaters  \n",
       "20723         Bottoms     Skirts  \n",
       "17409            Tops      Knits  \n",
       "7983             Tops    Blouses  \n",
       "5195          Bottoms      Pants  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15748</td>\n",
       "      <td>18095</td>\n",
       "      <td>18776</td>\n",
       "      <td>18776</td>\n",
       "      <td>18776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11431</td>\n",
       "      <td>18093</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Love it!</td>\n",
       "      <td>Perfect fit and i've gotten so many compliment...</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "      <td>11081</td>\n",
       "      <td>8377</td>\n",
       "      <td>5024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Title                                        Review Text  \\\n",
       "count      15748                                              18095   \n",
       "unique     11431                                              18093   \n",
       "top     Love it!  Perfect fit and i've gotten so many compliment...   \n",
       "freq         106                                                  2   \n",
       "\n",
       "       Division Name Department Name Class Name  \n",
       "count          18776           18776      18776  \n",
       "unique             3               6         20  \n",
       "top          General            Tops    Dresses  \n",
       "freq           11081            8377       5024  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe(include=np.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>18788.000000</td>\n",
       "      <td>18788.000000</td>\n",
       "      <td>18788.000000</td>\n",
       "      <td>18788.000000</td>\n",
       "      <td>18788.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>919.561369</td>\n",
       "      <td>43.170055</td>\n",
       "      <td>4.197999</td>\n",
       "      <td>0.822706</td>\n",
       "      <td>2.534330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>201.384374</td>\n",
       "      <td>12.285153</td>\n",
       "      <td>1.107503</td>\n",
       "      <td>0.381927</td>\n",
       "      <td>5.708134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>861.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>936.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1078.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1205.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Clothing ID           Age        Rating  Recommended IND  \\\n",
       "count  18788.000000  18788.000000  18788.000000     18788.000000   \n",
       "mean     919.561369     43.170055      4.197999         0.822706   \n",
       "std      201.384374     12.285153      1.107503         0.381927   \n",
       "min        0.000000     18.000000      1.000000         0.000000   \n",
       "25%      861.000000     34.000000      4.000000         1.000000   \n",
       "50%      936.000000     41.000000      5.000000         1.000000   \n",
       "75%     1078.000000     52.000000      5.000000         1.000000   \n",
       "max     1205.000000     99.000000      5.000000         1.000000   \n",
       "\n",
       "       Positive Feedback Count  \n",
       "count             18788.000000  \n",
       "mean                  2.534330  \n",
       "std                   5.708134  \n",
       "min                   0.000000  \n",
       "25%                   0.000000  \n",
       "50%                   1.000000  \n",
       "75%                   3.000000  \n",
       "max                 122.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the data and training parameters we will use.\n",
    "For model we can specify any supported HuggingFace model classes (see README for more details) as well as any AutoModel that are from the supported model classes. For the data specifications, we need to specify a dictionary that specifies which columns are the `text` columns, `numerical feature` columns, `categorical feature` column, and the `label` column. If we are doing classification, we can also specify what each of the labels means in the label column through the `label list`. We can also specifiy these columns using a path to a json file with the argument `column_info_path` to `MultimodalDataTrainingArguments`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_cols = ['Title', 'Review Text']\n",
    "cat_cols = ['Clothing ID', 'Division Name', 'Department Name', 'Class Name']\n",
    "numerical_cols = ['Rating', 'Age', 'Positive Feedback Count']\n",
    "\n",
    "column_info_dict = {\n",
    "    'text_cols': text_cols,\n",
    "    'num_cols': numerical_cols,\n",
    "    'cat_cols': cat_cols,\n",
    "    'label_col': 'Recommended IND',\n",
    "    'label_list': ['Not Recommended', 'Recommended']\n",
    "}\n",
    "\n",
    "\n",
    "model_args = ModelArguments(\n",
    "    model_name_or_path='bert-base-uncased'\n",
    ")\n",
    "\n",
    "data_args = MultimodalDataTrainingArguments(\n",
    "    data_path=DATA_DIR,\n",
    "    combine_feat_method='gating_on_cat_and_num_feats_then_sum',\n",
    "    column_info=column_info_dict,\n",
    "    task='classification'\n",
    ")\n",
    "\n",
    "training_args = OurTrainingArguments(\n",
    "    output_dir=\"./logs/model_name\",\n",
    "    logging_dir=\"./logs/runs\",\n",
    "    overwrite_output_dir=True,\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    per_device_train_batch_size=32,\n",
    "    num_train_epochs=1,\n",
    "    logging_steps=250,\n",
    "    evaluate_during_training=True\n",
    ")\n",
    "\n",
    "set_seed(training_args.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We first instantiate our HuggingFace tokenizer\n",
    "This is needed to prepare our custom torch dataset. See `torch_dataset.py` for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:transformers.tokenization_utils_base:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specified tokenizer:  bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
    "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    tokenizer_path_or_name,\n",
    "    cache_dir=model_args.cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset csvs to torch datasets\n",
    "The function `load_data_from_folder` expects a path to a folder that contains `train.csv`, `test.csv`, and/or `val.csv` containing the respective split datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:load_data:1239 categorical columns\n",
      "INFO:load_data:3 numerical columns\n",
      "INFO:load_data:Text columns: ['Title', 'Review Text']\n",
      "INFO:load_data:Raw text example: Pretty but not for me [SEP] This sweater is very pretty, i love the knit and the cream color. for some reason it just didn't flow the way i wanted it to, and i didn't love the v neck. just didn't pull me in completely!\n",
      "INFO:load_data:1239 categorical columns\n",
      "INFO:load_data:3 numerical columns\n",
      "INFO:load_data:Text columns: ['Title', 'Review Text']\n",
      "INFO:load_data:Raw text example: Great idea, poor execution [SEP] I absolutely loved the idea of an elongated hoodie as a lounge dress or robe. unfortunately, this particular product left a lot to be desired. firstly, the fit is slim, not relaxed. i'm 5'4\", at 110 lbs and tried both the size 1 (equivalent of a small) and size 2 (equivalent of a medium). sizing up just added length and did not do much to increase roominess. they both zipped up easily but did not drape well. finally, the fabric was really not welcoming. i prefer terry over fleece, however this w\n",
      "INFO:load_data:1239 categorical columns\n",
      "INFO:load_data:3 numerical columns\n",
      "INFO:load_data:Text columns: ['Title', 'Review Text']\n",
      "INFO:load_data:Raw text example: Fun and flirty [SEP] So pretty, love hte design on this one.\n",
      "i tried on hte regualr size, adn will not need a petite, it hit me jsut above my knee. younger gals may oprefer shorter, however.\n",
      "\n",
      "the aottern is also nice. the cut is flowy and flattering, nothing bad to say about htis dress...\n"
     ]
    }
   ],
   "source": [
    "# Get Datasets\n",
    "train_dataset, val_dataset, test_dataset = load_data_from_folder(\n",
    "    data_args.data_path,\n",
    "    data_args.column_info['text_cols'],\n",
    "    tokenizer,\n",
    "    label_col=data_args.column_info['label_col'],\n",
    "    label_list=data_args.column_info['label_list'],\n",
    "    categorical_cols=data_args.column_info['cat_cols'],\n",
    "    numerical_cols=data_args.column_info['num_cols'],\n",
    "    sep_text_token_str=tokenizer.sep_token,\n",
    "    max_token_length=training_args.max_token_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if data_args.task == 'regression':\n",
    "    num_labels = 1\n",
    "else:\n",
    "    num_labels = len(np.unique(train_dataset.labels))\n",
    "num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.configuration_utils:loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at /home/ec2-user/.cache/torch/transformers/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "INFO:transformers.configuration_utils:Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "    )\n",
    "tabular_config = TabularConfig(num_labels=num_labels,\n",
    "                               cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
    "                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
    "                               **vars(data_args))\n",
    "config.tabular_config = tabular_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at /home/ec2-user/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "WARNING:transformers.modeling_utils:Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertWithTabular: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertWithTabular from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertWithTabular from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "WARNING:transformers.modeling_utils:Some weights of BertWithTabular were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias', 'tabular_combiner.h_bias', 'tabular_combiner.num_bn.weight', 'tabular_combiner.num_bn.bias', 'tabular_combiner.num_bn.running_mean', 'tabular_combiner.num_bn.running_var', 'tabular_combiner.cat_layer.layers.0.weight', 'tabular_combiner.cat_layer.layers.0.bias', 'tabular_combiner.g_cat_layer.weight', 'tabular_combiner.g_cat_layer.bias', 'tabular_combiner.h_cat_layer.weight', 'tabular_combiner.g_num_layer.weight', 'tabular_combiner.g_num_layer.bias', 'tabular_combiner.h_num_layer.weight', 'tabular_combiner.layer_norm.weight', 'tabular_combiner.layer_norm.bias', 'tabular_classifier.weight', 'tabular_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelWithTabular.from_pretrained(\n",
    "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "        config=config,\n",
    "        cache_dir=model_args.cache_dir\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We need to define a task-specific way of computing relevant metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_compute_metrics_fn(task_name: str) -> Callable[[EvalPrediction], Dict]:\n",
    "    def compute_metrics_fn(p: EvalPrediction):\n",
    "        if task_name == \"classification\":\n",
    "            preds_labels = np.argmax(p.predictions, axis=1)\n",
    "            pred_scores = softmax(p.predictions, axis=1)[:, 1]\n",
    "            return calc_classification_metrics(pred_scores, preds_labels,\n",
    "                                               p.label_ids)\n",
    "        elif task_name == \"regression\":\n",
    "            preds = np.squeeze(p.predictions)\n",
    "            return calc_regression_metrics(preds, p.label_ids)\n",
    "        else:\n",
    "            return {}\n",
    "    return compute_metrics_fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:args:PyTorch: setting up devices\n",
      "INFO:transformers.trainer:You are instantiating a Trainer but W&B is not installed. To use wandb logging, run `pip install wandb; wandb login` see https://docs.wandb.com/huggingface.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=build_compute_metrics_fn(data_args.task),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Launching the training is as simple is doing trainer.train() ðŸ¤—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:***** Running training *****\n",
      "INFO:transformers.trainer:  Num examples = 18788\n",
      "INFO:transformers.trainer:  Num Epochs = 1\n",
      "INFO:transformers.trainer:  Instantaneous batch size per device = 16\n",
      "INFO:transformers.trainer:  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "INFO:transformers.trainer:  Gradient Accumulation steps = 1\n",
      "INFO:transformers.trainer:  Total optimization steps = 1175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4666539b2449249c9ea5c28a826b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='iâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171c628db36549c6910858b8525df65c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=1175.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'loss': 0.22426292389631272, 'learning_rate': 3.936170212765958e-05, 'epoch': 0.2127659574468085, 'step': 250}\n",
      "INFO:transformers.trainer:***** Running Evaluation *****\n",
      "INFO:transformers.trainer:  Num examples = 2349\n",
      "INFO:transformers.trainer:  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f2b0d14f20140e1a4042b9fb80e2c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=294.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'eval_loss': 0.14863149721656932, 'eval_roc_auc': 0.9812131588602175, 'eval_threshold': 0.31695735454559326, 'eval_pr_auc': 0.9958951737185882, 'eval_recall': 0.9641372141372141, 'eval_precision': 0.9722222222222222, 'eval_f1': 0.9681628392484343, 'eval_tn': 395, 'eval_fp': 30, 'eval_fn': 104, 'eval_tp': 1820, 'epoch': 0.2127659574468085, 'step': 250}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'loss': 0.16300668650865555, 'learning_rate': 2.8723404255319154e-05, 'epoch': 0.425531914893617, 'step': 500}\n",
      "INFO:transformers.trainer:***** Running Evaluation *****\n",
      "INFO:transformers.trainer:  Num examples = 2349\n",
      "INFO:transformers.trainer:  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0fe1afd870433e8788c1ac8f7f4572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=294.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'eval_loss': 0.14895194406513454, 'eval_roc_auc': 0.981175247645836, 'eval_threshold': 0.35274699330329895, 'eval_pr_auc': 0.9957904489018825, 'eval_recall': 0.9589397089397089, 'eval_precision': 0.9787798408488063, 'eval_f1': 0.9687582042530849, 'eval_tn': 400, 'eval_fp': 25, 'eval_fn': 107, 'eval_tp': 1817, 'epoch': 0.425531914893617, 'step': 500}\n",
      "INFO:transformers.trainer:Saving model checkpoint to ./logs/model_name/checkpoint-500\n",
      "INFO:transformers.configuration_utils:Configuration saved in ./logs/model_name/checkpoint-500/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:Model weights saved in ./logs/model_name/checkpoint-500/pytorch_model.bin\n",
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "INFO:transformers.trainer:{'loss': 0.15592467722296716, 'learning_rate': 1.8085106382978724e-05, 'epoch': 0.6382978723404256, 'step': 750}\n",
      "INFO:transformers.trainer:***** Running Evaluation *****\n",
      "INFO:transformers.trainer:  Num examples = 2349\n",
      "INFO:transformers.trainer:  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81ce64498453492f8bb46ceeb60d6fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=294.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'eval_loss': 0.14800560437332916, 'eval_roc_auc': 0.9815739268680446, 'eval_threshold': 0.8034530282020569, 'eval_pr_auc': 0.9960075810375029, 'eval_recall': 0.9563409563409564, 'eval_precision': 0.9740603493912123, 'eval_f1': 0.965119328612641, 'eval_tn': 332, 'eval_fp': 93, 'eval_fn': 51, 'eval_tp': 1873, 'epoch': 0.6382978723404256, 'step': 750}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'loss': 0.13811917620897293, 'learning_rate': 7.446808510638298e-06, 'epoch': 0.851063829787234, 'step': 1000}\n",
      "INFO:transformers.trainer:***** Running Evaluation *****\n",
      "INFO:transformers.trainer:  Num examples = 2349\n",
      "INFO:transformers.trainer:  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a7b2b38f344cc7a3c99b1b3f9fe1b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=294.0, style=ProgressStyle(description_wâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.trainer:{'eval_loss': 0.14000431921643516, 'eval_roc_auc': 0.9828402837226368, 'eval_threshold': 0.3892201781272888, 'eval_pr_auc': 0.9962478798144302, 'eval_recall': 0.9615384615384616, 'eval_precision': 0.9721492380451918, 'eval_f1': 0.9668147373922132, 'eval_tn': 382, 'eval_fp': 43, 'eval_fn': 88, 'eval_tp': 1836, 'epoch': 0.851063829787234, 'step': 1000}\n",
      "INFO:transformers.trainer:Saving model checkpoint to ./logs/model_name/checkpoint-1000\n",
      "INFO:transformers.configuration_utils:Configuration saved in ./logs/model_name/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.modeling_utils:Model weights saved in ./logs/model_name/checkpoint-1000/pytorch_model.bin\n",
      "/home/ec2-user/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:200: UserWarning: Please also save or load the state of the optimzer when saving or loading the scheduler.\n",
      "  warnings.warn(SAVE_STATE_WARNING, UserWarning)\n",
      "INFO:transformers.trainer:\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CPU times: user 3min 24s, sys: 40.8 s, total: 4min 4s\n",
      "Wall time: 4min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1175, training_loss=0.16534934793380981)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that our training was successful using TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 8009 (pid 15486), started 0:00:26 ago. (Use '!kill 15486' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdd640fb06671ad1\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdd640fb06671ad1\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir ./logs/runs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}