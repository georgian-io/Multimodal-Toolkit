{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZR8kqmfRssU"
      },
      "source": [
        "# Training a Longformer Model for Clothing Review Recommendation Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jixkQU9wRssV"
      },
      "source": [
        "This guide follows closely with the [example](https://colab.research.google.com/github/huggingface/blog/blob/master/notebooks/trainer/01_text_classification.ipynb#scrollTo=bwl3I_VGAZXb) from HuggingFace for text classificaion on the GLUE dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UWEp8fjltYc5",
        "outputId": "e803fc35-5c9f-4ce0-b73d-bcf2f32a93d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May  4 19:11:27 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.85.12    Driver Version: 525.85.12    CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P0    43W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
            "|                               |                      |             Disabled |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbmTRG_WtaEz",
        "outputId": "fafafaac-dc1b-4554-b840-8f3763ec5512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 89.6 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E087JXkO__-X",
        "outputId": "07993a6f-f801-4d22-ddbe-04d1ac434ef5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/jtfields/Multimodal-Toolkit-Longformer.git\n",
            "  Cloning https://github.com/jtfields/Multimodal-Toolkit-Longformer.git to /tmp/pip-req-build-k62_ntup\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/jtfields/Multimodal-Toolkit-Longformer.git /tmp/pip-req-build-k62_ntup\n",
            "  Resolved https://github.com/jtfields/Multimodal-Toolkit-Longformer.git to commit 29a73f42eb7cd832a8220a410bc5bd3e24661bbb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers>=4.26.1\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from multimodal-transformers==0.2a0) (2.0.0+cu118)\n",
            "Collecting sacremoses~=0.0.53\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting networkx~=2.6.3\n",
            "  Downloading networkx-2.6.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn~=1.0.2\n",
            "  Downloading scikit_learn-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy~=1.7.3\n",
            "  Downloading scipy-1.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas~=1.3.5\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy~=1.21.6\n",
            "  Downloading numpy-1.21.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m97.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm~=4.64.1\n",
            "  Downloading tqdm-4.64.1-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest~=7.2.2 in /usr/local/lib/python3.10/dist-packages (from multimodal-transformers==0.2a0) (7.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.3.5->multimodal-transformers==0.2a0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.10/dist-packages (from pandas~=1.3.5->multimodal-transformers==0.2a0) (2022.7.1)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from pytest~=7.2.2->multimodal-transformers==0.2a0) (23.1.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest~=7.2.2->multimodal-transformers==0.2a0) (1.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest~=7.2.2->multimodal-transformers==0.2a0) (23.1)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest~=7.2.2->multimodal-transformers==0.2a0) (2.0.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest~=7.2.2->multimodal-transformers==0.2a0) (1.1.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest~=7.2.2->multimodal-transformers==0.2a0) (2.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses~=0.0.53->multimodal-transformers==0.2a0) (2022.10.31)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses~=0.0.53->multimodal-transformers==0.2a0) (1.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses~=0.0.53->multimodal-transformers==0.2a0) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses~=0.0.53->multimodal-transformers==0.2a0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn~=1.0.2->multimodal-transformers==0.2a0) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->multimodal-transformers==0.2a0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->multimodal-transformers==0.2a0) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->multimodal-transformers==0.2a0) (3.1.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->multimodal-transformers==0.2a0) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->multimodal-transformers==0.2a0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.1->multimodal-transformers==0.2a0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.13.1->multimodal-transformers==0.2a0) (16.0.2)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m114.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->multimodal-transformers==0.2a0) (2.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.26.1->multimodal-transformers==0.2a0) (6.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers>=4.26.1->multimodal-transformers==0.2a0) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.1->multimodal-transformers==0.2a0) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers==0.2a0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers==0.2a0) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers==0.2a0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.26.1->multimodal-transformers==0.2a0) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->multimodal-transformers==0.2a0) (1.3.0)\n",
            "Building wheels for collected packages: multimodal-transformers, sacremoses\n",
            "  Building wheel for multimodal-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for multimodal-transformers: filename=multimodal_transformers-0.2a0-py3-none-any.whl size=22778 sha256=e92681b6fd1e740650ffb6f429042280b5be30232ef3944f28f62ff09855b87a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7d8ltwjr/wheels/e8/a1/15/33011bceb32815e8c04a5dfc8c9eec8b5a2238e47ac97f930b\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895259 sha256=0a7a67f063545c701cc9d035a858d0f8d0925f44166328a3245132969a449ea3\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "Successfully built multimodal-transformers sacremoses\n",
            "Installing collected packages: tokenizers, tqdm, numpy, networkx, scipy, sacremoses, pandas, huggingface-hub, transformers, scikit-learn, multimodal-transformers\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.1\n",
            "    Uninstalling networkx-3.1:\n",
            "      Successfully uninstalled networkx-3.1\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.12.0 requires numpy<1.24,>=1.22, but you have numpy 1.21.6 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas~=1.5.3, but you have pandas 1.3.5 which is incompatible.\n",
            "arviz 0.15.1 requires scipy>=1.8.0, but you have scipy 1.7.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed huggingface-hub-0.14.1 multimodal-transformers-0.2a0 networkx-2.6.3 numpy-1.21.6 pandas-1.3.5 sacremoses-0.0.53 scikit-learn-1.0.2 scipy-1.7.3 tokenizers-0.13.3 tqdm-4.64.1 transformers-4.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/jtfields/Multimodal-Toolkit-Longformer.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4-_eQS4QLYp",
        "outputId": "fbe7cd9d-4e82-4037-8703-9609e1e31c4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rB2JjhkXRssl"
      },
      "outputs": [],
      "source": [
        "#from google.colab import files\n",
        "#files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpFSVqyVRss1"
      },
      "source": [
        "## All other imports are here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Scm6cPeURss2"
      },
      "outputs": [],
      "source": [
        "from dataclasses import dataclass, field\n",
        "import json\n",
        "import logging\n",
        "import os\n",
        "from typing import Optional\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    Trainer,\n",
        "    EvalPrediction,\n",
        "    set_seed\n",
        ")\n",
        "from transformers.training_args import TrainingArguments\n",
        "\n",
        "from multimodal_transformers.data import load_data_from_folder\n",
        "from multimodal_transformers.model import TabularConfig\n",
        "from multimodal_transformers.model import AutoModelWithTabular\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "os.environ['COMET_MODE'] = 'DISABLED'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjUqUXgpRstr"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "Our dataset is the [Womens Clothing E-Commerce Reviews](https://www.kaggle.com/nicapotato/womens-ecommerce-clothing-reviews) dataset from kaggle. It contains reviews written by customers about clothing items as well as whether they recommend the data or not. We download the dataset here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVNx_Xd8Rst6"
      },
      "source": [
        "#### Let us take a look at what the dataset looks like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ql8mJlKAUWX5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b5f8fea0-95c2-44dd-99b5-e04dfb7871d0"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-ffcca9ff6e7d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Colab Notebooks/Longformer/Womens Clothing E-Commerce Reviews.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "data_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Longformer/Womens Clothing E-Commerce Reviews.csv')\n",
        "data_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample the dataframe to reduce the file size so trainer can run\n",
        "data_df = data_df.sample(n=100, random_state=1)"
      ],
      "metadata": {
        "id": "GrDqLsGkHBBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe8-dirpUjg8"
      },
      "source": [
        "We see that the data contains both text in the `Review Text` and `Title` column as well as tabular features in the `Division Name`, `Department Name`, and `Class Name` columns. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpzF_0erRsuI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "4168d883-3a1f-4505-be64-79b4b45476ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5fc129dc0c45>:1: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  data_df.describe(include=np.object)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                            Title  \\\n",
              "count                          34   \n",
              "unique                         34   \n",
              "top     Perfect for work and play   \n",
              "freq                            1   \n",
              "\n",
              "                                              Review Text Division Name  \\\n",
              "count                                                  39            40   \n",
              "unique                                                 39             3   \n",
              "top     This shirt works for both going out and going ...       General   \n",
              "freq                                                    1            26   \n",
              "\n",
              "       Department Name Class Name  \n",
              "count               40         40  \n",
              "unique               5         12  \n",
              "top               Tops      Knits  \n",
              "freq                19         14  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-99fdc3a8-b5f5-452b-aa47-8c4f90855dc2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Review Text</th>\n",
              "      <th>Division Name</th>\n",
              "      <th>Department Name</th>\n",
              "      <th>Class Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>34</td>\n",
              "      <td>39</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "      <td>40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>34</td>\n",
              "      <td>39</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>Perfect for work and play</td>\n",
              "      <td>This shirt works for both going out and going ...</td>\n",
              "      <td>General</td>\n",
              "      <td>Tops</td>\n",
              "      <td>Knits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>26</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99fdc3a8-b5f5-452b-aa47-8c4f90855dc2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-99fdc3a8-b5f5-452b-aa47-8c4f90855dc2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-99fdc3a8-b5f5-452b-aa47-8c4f90855dc2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data_df.describe(include=np.object)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSFD6Jl0RsuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "451a2c6d-bc25-4d41-be63-661b2446bdc3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         Unnamed: 0  Clothing ID        Age     Rating  Recommended IND  \\\n",
              "count     40.000000    40.000000  40.000000  40.000000        40.000000   \n",
              "mean    9813.475000   939.675000  41.325000   4.075000         0.700000   \n",
              "std     5579.685466   159.714551  11.064815   1.163273         0.464095   \n",
              "min     1113.000000   288.000000  20.000000   1.000000         0.000000   \n",
              "25%     5215.750000   863.500000  33.500000   3.000000         0.000000   \n",
              "50%     9402.000000   919.500000  41.500000   5.000000         1.000000   \n",
              "75%    14173.500000  1069.000000  48.000000   5.000000         1.000000   \n",
              "max    21298.000000  1116.000000  62.000000   5.000000         1.000000   \n",
              "\n",
              "       Positive Feedback Count  \n",
              "count                40.000000  \n",
              "mean                  3.250000  \n",
              "std                   5.655721  \n",
              "min                   0.000000  \n",
              "25%                   0.000000  \n",
              "50%                   1.000000  \n",
              "75%                   4.000000  \n",
              "max                  26.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcdf4683-2830-47a8-8a56-a2d7338d0df8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Clothing ID</th>\n",
              "      <th>Age</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Recommended IND</th>\n",
              "      <th>Positive Feedback Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>40.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>9813.475000</td>\n",
              "      <td>939.675000</td>\n",
              "      <td>41.325000</td>\n",
              "      <td>4.075000</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>3.250000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>5579.685466</td>\n",
              "      <td>159.714551</td>\n",
              "      <td>11.064815</td>\n",
              "      <td>1.163273</td>\n",
              "      <td>0.464095</td>\n",
              "      <td>5.655721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1113.000000</td>\n",
              "      <td>288.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5215.750000</td>\n",
              "      <td>863.500000</td>\n",
              "      <td>33.500000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>9402.000000</td>\n",
              "      <td>919.500000</td>\n",
              "      <td>41.500000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>14173.500000</td>\n",
              "      <td>1069.000000</td>\n",
              "      <td>48.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>21298.000000</td>\n",
              "      <td>1116.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>26.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcdf4683-2830-47a8-8a56-a2d7338d0df8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcdf4683-2830-47a8-8a56-a2d7338d0df8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcdf4683-2830-47a8-8a56-a2d7338d0df8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOqO-hyaV6Dr"
      },
      "source": [
        "In this demonstration, we split our data into 8:1:1 training splits. We also save our splits to `train.csv`, `val.csv`, and `test.csv` as this is the format our dataloader requires.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ41PkSZRsts",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "246061ea-3584-4964-af86-f0b21c6486c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples train-val-test\n",
            "32 4 4\n"
          ]
        }
      ],
      "source": [
        "train_df, val_df, test_df = np.split(data_df.sample(frac=1), [int(.8*len(data_df)), int(.9 * len(data_df))])\n",
        "print('Num examples train-val-test')\n",
        "print(len(train_df), len(val_df), len(test_df))\n",
        "train_df.to_csv('train.csv')\n",
        "val_df.to_csv('val.csv')\n",
        "test_df.to_csv('test.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XA5z7WTqWV0A"
      },
      "source": [
        "## We then our Experiment Parameters\n",
        "We use Data Classes to hold each of our arguments for the model, data, and training. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNg22DHEWueA"
      },
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ModelArguments:\n",
        "  \"\"\"\n",
        "  Arguments pertaining to which model/config/tokenizer we are going to fine-tune from.\n",
        "  \"\"\"\n",
        "\n",
        "  model_name_or_path: str = field(\n",
        "      metadata={\"help\": \"Path to pretrained model or model identifier from huggingface.co/models\"}\n",
        "  )\n",
        "  config_name: Optional[str] = field(\n",
        "      default=None, metadata={\"help\": \"Pretrained config name or path if not the same as model_name\"}\n",
        "  )\n",
        "  tokenizer_name: Optional[str] = field(\n",
        "      default=None, metadata={\"help\": \"Pretrained tokenizer name or path if not the same as model_name\"}\n",
        "  )\n",
        "  cache_dir: Optional[str] = field(\n",
        "      default=None, metadata={\"help\": \"Where do you want to store the pretrained models downloaded from s3\"}\n",
        "  )\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class MultimodalDataTrainingArguments:\n",
        "  \"\"\"\n",
        "  Arguments pertaining to how we combine tabular features\n",
        "  Using `HfArgumentParser` we can turn this class\n",
        "  into argparse arguments to be able to specify them on\n",
        "  the command line.\n",
        "  \"\"\"\n",
        "\n",
        "  data_path: str = field(metadata={\n",
        "                            'help': 'the path to the csv file containing the dataset'\n",
        "                        })\n",
        "  column_info_path: str = field(\n",
        "      #default='/content/column_info.json',\n",
        "      default=None,\n",
        "      metadata={\n",
        "          'help': 'the path to the json file detailing which columns are text, categorical, numerical, and the label'\n",
        "  })\n",
        "\n",
        "  column_info: dict = field(\n",
        "      default=None,\n",
        "      metadata={\n",
        "          'help': 'a dict referencing the text, categorical, numerical, and label columns'\n",
        "                  'its keys are text_cols, num_cols, cat_cols, and label_col'\n",
        "  })\n",
        "\n",
        "  categorical_encode_type: str = field(default='ohe',\n",
        "                                        metadata={\n",
        "                                            'help': 'sklearn encoder to use for categorical data',\n",
        "                                            'choices': ['ohe', 'binary', 'label', 'none']\n",
        "                                        })\n",
        "  numerical_transformer_method: str = field(default='yeo_johnson',\n",
        "                                            metadata={\n",
        "                                                'help': 'sklearn numerical transformer to preprocess numerical data',\n",
        "                                                'choices': ['yeo_johnson', 'box_cox', 'quantile_normal', 'none']\n",
        "                                            })\n",
        "  task: str = field(default=\"classification\",\n",
        "                    metadata={\n",
        "                        \"help\": \"The downstream training task\",\n",
        "                        \"choices\": [\"classification\", \"regression\"]\n",
        "                    })\n",
        "\n",
        "  mlp_division: int = field(default=4,\n",
        "                            metadata={\n",
        "                                'help': 'the ratio of the number of '\n",
        "                                        'hidden dims in a current layer to the next MLP layer'\n",
        "                            })\n",
        "  combine_feat_method: str = field(default='individual_mlps_on_cat_and_numerical_feats_then_concat',\n",
        "                                    metadata={\n",
        "                                        'help': 'method to combine categorical and numerical features, '\n",
        "                                                'see README for all the method'\n",
        "                                    })\n",
        "  mlp_dropout: float = field(default=0.1,\n",
        "                              metadata={\n",
        "                                'help': 'dropout ratio used for MLP layers'\n",
        "                              })\n",
        "  numerical_bn: bool = field(default=True,\n",
        "                              metadata={\n",
        "                                  'help': 'whether to use batchnorm on numerical features'\n",
        "                              })\n",
        "  use_simple_classifier: str = field(default=True,\n",
        "                                      metadata={\n",
        "                                          'help': 'whether to use single layer or MLP as final classifier'\n",
        "                                      })\n",
        "  mlp_act: str = field(default='relu',\n",
        "                        metadata={\n",
        "                            'help': 'the activation function to use for finetuning layers',\n",
        "                            'choices': ['relu', 'prelu', 'sigmoid', 'tanh', 'linear']\n",
        "                        })\n",
        "  gating_beta: float = field(default=0.2,\n",
        "                              metadata={\n",
        "                                  'help': \"the beta hyperparameters used for gating tabular data \"\n",
        "                                          \"see https://www.aclweb.org/anthology/2020.acl-main.214.pdf\"\n",
        "                              })\n",
        "\n",
        "  def __post_init__(self):\n",
        "      assert self.column_info != self.column_info_path\n",
        "      if self.column_info is None and self.column_info_path:\n",
        "          with open(self.column_info_path, 'r') as f:\n",
        "              self.column_info = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZC5ds3lRsuS"
      },
      "source": [
        "### Here are the data and training parameters we will use.\n",
        "For model we can specify any supported HuggingFace model classes (see README for more details) as well as any AutoModel that are from the supported model classes. For the data specifications, we need to specify a dictionary that specifies which columns are the `text` columns, `numerical feature` columns, `categorical feature` column, and the `label` column. If we are doing classification, we can also specify what each of the labels means in the label column through the `label list`. We can also specifiy these columns using a path to a json file with the argument `column_info_path` to `MultimodalDataTrainingArguments`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGjGmetXRsuS"
      },
      "outputs": [],
      "source": [
        "text_cols = ['Title', 'Review Text']\n",
        "cat_cols = ['Clothing ID', 'Division Name', 'Department Name', 'Class Name']\n",
        "numerical_cols = ['Rating', 'Age', 'Positive Feedback Count']\n",
        "\n",
        "column_info_dict = {\n",
        "    'text_cols': text_cols,\n",
        "    'num_cols': numerical_cols,\n",
        "    'cat_cols': cat_cols,\n",
        "    'label_col': 'Recommended IND',\n",
        "    'label_list': ['Not Recommended', 'Recommended']\n",
        "}\n",
        "\n",
        "\n",
        "model_args = ModelArguments(\n",
        "    model_name_or_path=('allenai/longformer-base-4096')\n",
        ")\n",
        "\n",
        "data_args = MultimodalDataTrainingArguments(\n",
        "    data_path='.',\n",
        "    combine_feat_method='individual_mlps_on_cat_and_numerical_feats_then_concat',\n",
        "    #combine_feat_method='mlp_on_concatenated_cat_and_numerical_feats_then_concat',\n",
        "    #combine_feat_method='attention_on_cat_and_numerical_feats',\n",
        "    #combine_feat_method='concat',\n",
        "    column_info=column_info_dict,\n",
        "    task='classification'\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./logs/model_name\",\n",
        "    logging_dir=\"./logs/runs\",\n",
        "    overwrite_output_dir=True,\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    per_device_train_batch_size=32,\n",
        "    num_train_epochs=1,\n",
        "    #evaluate_during_training=True,\n",
        "    evaluation_strategy='epoch',\n",
        "    logging_steps=25,\n",
        "    eval_steps=250\n",
        ")\n",
        "\n",
        "set_seed(training_args.seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ErHoD6pRsuZ"
      },
      "source": [
        "## Now we can load our model and data. \n",
        "### We first instantiate our HuggingFace tokenizer\n",
        "This is needed to prepare our custom torch dataset. See `torch_dataset.py` for details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "38GJb0Y7RsuZ"
      },
      "outputs": [],
      "source": [
        "tokenizer_path_or_name = model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path\n",
        "print('Specified tokenizer: ', tokenizer_path_or_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    tokenizer_path_or_name,\n",
        "    cache_dir=model_args.cache_dir,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from transformers import LongformerTokenizer, LongformerForSequenceClassification\n",
        "#tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "#model = LongformerForSequenceClassification.from_pretrained('allenai/longformer-base-4096', return_dict=True)\n"
      ],
      "metadata": {
        "id": "UJLRU6T47EVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5isn9Lxc_2Uq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "317d4308-e58f-4bf1-ea36-21a6c3fe3e7d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultimodalDataTrainingArguments(data_path='.', column_info_path=None, column_info={'text_cols': ['Title', 'Review Text'], 'num_cols': ['Rating', 'Age', 'Positive Feedback Count'], 'cat_cols': ['Clothing ID', 'Division Name', 'Department Name', 'Class Name'], 'label_col': 'Recommended IND', 'label_list': ['Not Recommended', 'Recommended']}, categorical_encode_type='ohe', numerical_transformer_method='yeo_johnson', task='classification', mlp_division=4, combine_feat_method='individual_mlps_on_cat_and_numerical_feats_then_concat', mlp_dropout=0.1, numerical_bn=True, use_simple_classifier=True, mlp_act='relu', gating_beta=0.2)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "data_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ui_SgHwKVPn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5298ce81-a2cc-4312-be03-a8365bde1a6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModelArguments(model_name_or_path='allenai/longformer-base-4096', config_name=None, tokenizer_name=None, cache_dir=None)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "model_args"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KC7GI8kVKc2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4675d408-6dbe-4758-ca77-548b51b1f132"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_pin_memory=True,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=True,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_steps=250,\n",
              "evaluation_strategy=epoch,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'fsdp_min_num_params': 0, 'xla': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "greater_is_better=None,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=False,\n",
              "hub_strategy=every_save,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_inputs_for_metrics=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=5e-05,\n",
              "length_column_name=length,\n",
              "load_best_model_at_end=False,\n",
              "local_rank=-1,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./logs/runs,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=25,\n",
              "logging_strategy=steps,\n",
              "lr_scheduler_type=linear,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=None,\n",
              "mp_parameters=,\n",
              "no_cuda=False,\n",
              "num_train_epochs=1,\n",
              "optim=adamw_hf,\n",
              "optim_args=None,\n",
              "output_dir=./logs/model_name,\n",
              "overwrite_output_dir=True,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=8,\n",
              "per_device_train_batch_size=32,\n",
              "prediction_loss_only=False,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['tensorboard'],\n",
              "resume_from_checkpoint=None,\n",
              "run_name=./logs/model_name,\n",
              "save_on_each_node=False,\n",
              "save_safetensors=False,\n",
              "save_steps=500,\n",
              "save_strategy=steps,\n",
              "save_total_limit=None,\n",
              "seed=42,\n",
              "sharded_ddp=[],\n",
              "skip_memory_metrics=True,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "use_ipex=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.0,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.0,\n",
              "xpu_backend=None,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "training_args"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-f4bMPLRsue"
      },
      "source": [
        "### Load dataset csvs to torch datasets\n",
        "The function `load_data_from_folder` expects a path to a folder that contains `train.csv`, `test.csv`, and/or `val.csv` containing the respective split datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xz7LHXFoRsue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83310a05-4965-4c70-f5a3-6177741d3c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py:2590: UserWarning: n_quantiles (1000) is greater than the total number of samples (32). n_quantiles is set to n_samples.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/numpy/lib/nanfunctions.py:1560: RuntimeWarning: All-NaN slice encountered\n",
            "  isbad = (dof <= 0)\n"
          ]
        }
      ],
      "source": [
        "# Get Datasets\n",
        "train_dataset, val_dataset, test_dataset = load_data_from_folder(\n",
        "    data_args.data_path,\n",
        "    data_args.column_info['text_cols'],\n",
        "    tokenizer,\n",
        "    label_col=data_args.column_info['label_col'],\n",
        "    label_list=data_args.column_info['label_list'],\n",
        "    categorical_cols=data_args.column_info['cat_cols'],\n",
        "    numerical_cols=data_args.column_info['num_cols'],\n",
        "    sep_text_token_str=tokenizer.sep_token,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ABT1hK9cRsuk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "696b4683-9d02-4a21-c0c5-4193e8985a93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "num_labels = len(np.unique(train_dataset.labels))\n",
        "num_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZV-kyVqRsun"
      },
      "outputs": [],
      "source": [
        "config = AutoConfig.from_pretrained(\n",
        "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "        cache_dir=model_args.cache_dir,\n",
        "    )\n",
        "tabular_config = TabularConfig(num_labels=num_labels,\n",
        "                               cat_feat_dim=train_dataset.cat_feats.shape[1],\n",
        "                               numerical_feat_dim=train_dataset.numerical_feats.shape[1],\n",
        "                               **vars(data_args))\n",
        "config.tabular_config = tabular_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXqprYO-Rsur",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d7400e8-4552-4447-c7f8-94f3341bb656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at allenai/longformer-base-4096 were not used when initializing LongformerWithTabular: ['lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
            "- This IS expected if you are initializing LongformerWithTabular from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LongformerWithTabular from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of LongformerWithTabular were not initialized from the model checkpoint at allenai/longformer-base-4096 and are newly initialized: ['tabular_combiner.num_mlp.layers.1.bias', 'classifier.dense.bias', 'tabular_combiner.num_mlp.layers.0.weight', 'classifier.out_proj.weight', 'classifier.out_proj.bias', 'tabular_combiner.num_mlp.bn.0.running_mean', 'tabular_combiner.cat_mlp.layers.0.bias', 'tabular_classifier.weight', 'tabular_combiner.num_mlp.layers.1.weight', 'tabular_combiner.num_bn.num_batches_tracked', 'tabular_combiner.num_bn.running_var', 'tabular_combiner.num_mlp.bn.0.num_batches_tracked', 'tabular_combiner.num_bn.running_mean', 'tabular_combiner.num_mlp.bn.0.bias', 'tabular_combiner.cat_mlp.layers.0.weight', 'tabular_combiner.num_bn.weight', 'tabular_combiner.num_mlp.bn.0.weight', 'tabular_combiner.num_bn.bias', 'tabular_combiner.num_mlp.layers.0.bias', 'tabular_combiner.num_mlp.bn.0.running_var', 'tabular_classifier.bias', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = AutoModelWithTabular.from_pretrained(\n",
        "        model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
        "        config=config,\n",
        "        cache_dir=model_args.cache_dir\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi7UsNvvRsux"
      },
      "source": [
        "### We need to define a task-specific way of computing relevant metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ww35P4MRsux"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.special import softmax\n",
        "from sklearn.metrics import (\n",
        "    auc,\n",
        "    precision_recall_curve,\n",
        "    roc_auc_score,\n",
        "    f1_score,\n",
        "    confusion_matrix,\n",
        "    matthews_corrcoef,\n",
        ")\n",
        "\n",
        "def calc_classification_metrics(p: EvalPrediction):\n",
        "  pred_labels = np.argmax(p.predictions, axis=1)\n",
        "  pred_scores = softmax(p.predictions, axis=1)[:, 1]\n",
        "  labels = p.label_ids\n",
        "  if len(np.unique(labels)) == 2:  # binary classification\n",
        "      roc_auc_pred_score = roc_auc_score(labels, pred_scores)\n",
        "      precisions, recalls, thresholds = precision_recall_curve(labels,\n",
        "                                                                pred_scores)\n",
        "      fscore = (2 * precisions * recalls) / (precisions + recalls)\n",
        "      fscore[np.isnan(fscore)] = 0\n",
        "      ix = np.argmax(fscore)\n",
        "      threshold = thresholds[ix].item()\n",
        "      pr_auc = auc(recalls, precisions)\n",
        "      tn, fp, fn, tp = confusion_matrix(labels, pred_labels, labels=[0, 1]).ravel()\n",
        "      result = {'roc_auc': roc_auc_pred_score,\n",
        "                'threshold': threshold,\n",
        "                'pr_auc': pr_auc,\n",
        "                'recall': recalls[ix].item(),\n",
        "                'precision': precisions[ix].item(), 'f1': fscore[ix].item(),\n",
        "                'tn': tn.item(), 'fp': fp.item(), 'fn': fn.item(), 'tp': tp.item()\n",
        "                }\n",
        "  else:\n",
        "      acc = (pred_labels == labels).mean()\n",
        "      f1 = f1_score(y_true=labels, y_pred=pred_labels)\n",
        "      result = {\n",
        "          \"acc\": acc,\n",
        "          \"f1\": f1,\n",
        "          \"acc_and_f1\": (acc + f1) / 2,\n",
        "          \"mcc\": matthews_corrcoef(labels, pred_labels)\n",
        "      }\n",
        "\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFeF6HTsRsu1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e09b2b59-dd07-4826-dba6-23685623a3c6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a6e05b271b83>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m trainer = Trainer(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_model_on_device\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"is_loaded_in_8bit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1894\u001b[0m             )\n\u001b[1;32m   1895\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1896\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhalf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1143\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1147\u001b[0m     def register_full_backward_pre_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    818\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 820\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    821\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m   1142\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m-> 1143\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 15.77 GiB total capacity; 14.70 GiB already allocated; 20.12 MiB free; 14.79 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=calc_classification_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "yHd4jXhhfE28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtWJoq6nRsvM"
      },
      "source": [
        "## Launching the training is as simple is doing trainer.train() 🤗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fHtN4yhdRsvN"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-NkufyHRsve"
      },
      "source": [
        "### Check that our training was successful using TensorBoard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rYE98-OKRsvf"
      },
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "#%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFTwBNQARsvm"
      },
      "outputs": [],
      "source": [
        "#%tensorboard --logdir ./logs/runs --port=6006"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}